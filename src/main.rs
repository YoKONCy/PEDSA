use aho_corasick::{AhoCorasick, AhoCorasickBuilder, MatchKind};
use ahash::AHashMap;
use smallvec::SmallVec;
use rayon::prelude::*;
use std::time::Instant;
use std::hash::{Hash, Hasher};
use twox_hash::XxHash64;
use half::f16;

mod dataset;
mod tests;
mod storage;
mod embedding;
mod inference_engine;
use storage::{generate_binary_dataset, StorageEngine, ChaosFingerprint};
use dataset::{get_tech_domain_data, get_social_domain_data, get_history_domain_data, get_value_domain_data, get_daily_domain_data, get_timeline_domain_data, get_ontology_data};
use embedding::CandleModel;

// ============================================================================
// 1. è¯­ä¹‰æŒ‡çº¹ (SimHash V2: Partitioned Multimodal)
// ============================================================================

pub struct SimHash;

impl SimHash {
    pub const MASK_SEMANTIC: u64 = 0xFFFFFFFF;
    pub const MASK_TEMPORAL: u64 = 0xFFFF00000000; // [32-47]: æ—¶é—´åŒº (ä»…æ—¶é—´ - V3 ä¸­å·²ç§»é™¤ä½ç½®)
    pub const MASK_AFFECTIVE: u64 = 0x00FF000000000000;
    pub const MASK_TYPE: u64 = 0xFF00000000000000;

    // --- å®ä½“ç±»å‹å¸¸é‡ ---
    pub const TYPE_UNKNOWN: u8 = 0x00;
    pub const TYPE_PERSON: u8 = 0x01;    // äººç‰©/èº«ä»½
    pub const TYPE_TECH: u8 = 0x02;      // æŠ€æœ¯/æ¦‚å¿µ
    pub const TYPE_EVENT: u8 = 0x03;     // äº‹ä»¶/åŠ¨ä½œ
    pub const TYPE_LOCATION: u8 = 0x04;  // åœ°ç‚¹
    pub const TYPE_OBJECT: u8 = 0x05;    // ç‰©ä»¶
    pub const TYPE_VALUES: u8 = 0x06;    // ä»·å€¼è§‚

    // --- è¾¹ç±»å‹å¸¸é‡ (V3.5 ç±»å‹åŒ–è¾¹ - ç®€åŒ–ç‰ˆ) ---
    pub const EDGE_REPRESENTATION: u8 = 0; // è¡¨å¾ (Representation) - "çœ‹åˆ° B å¯èƒ½ä¼šæƒ³åˆ° A" (å•å‘/éç­‰ä»·)
    pub const EDGE_EQUALITY: u8 = 1;       // ç­‰ä»· (Equality) - "A å°±æ˜¯ B" (åŒå‘/é›¶æŸè€—)
    pub const EDGE_INHIBITION: u8 = 255;   // æŠ‘åˆ¶ (Inhibition) - "A ä¸ B äº’æ–¥" (åŒå‘/è´Ÿåé¦ˆ)

    // --- æƒ…æ„Ÿå¸¸é‡ (Plutchik æƒ…æ„Ÿè½®ä½å›¾ - å·²è°ƒæ•´) ---
    pub const EMOTION_JOY: u8          = 1 << 0; // å–œæ‚¦
    pub const EMOTION_SHY: u8          = 1 << 1; // å®³ç¾
    pub const EMOTION_FEAR: u8         = 1 << 2; // å®³æ€•
    pub const EMOTION_SURPRISE: u8     = 1 << 3; // æƒŠè®¶
    pub const EMOTION_SADNESS: u8      = 1 << 4; // éš¾è¿‡
    pub const EMOTION_DISGUST: u8      = 1 << 5; // è®¨åŒ
    pub const EMOTION_ANGER: u8        = 1 << 6; // ç”Ÿæ°”
    pub const EMOTION_ANTICIPATION: u8 = 1 << 7; // æœŸå¾…

    /// è®¡ç®—å¤šæ¨¡æ€åˆ†åŒºæŒ‡çº¹ (64ä½)
    /// [0-31]: è¯­ä¹‰åŒº (æ–‡æœ¬)
    /// [32-47]: æ—¶é—´åŒº (æ—¶é—´)
    /// [48-55]: æƒ…æ„ŸåŒº (æƒ…æ„Ÿ)
    /// [56-63]: ç±»å‹åŒº (å®ä½“ç±»å‹)
    pub fn compute_multimodal(text: &str, timestamp: u64, emotion_val: u8, type_val: u8) -> u64 {
        let mut fp = 0u64;

        // 1. è¯­ä¹‰åŒº [0-31] (32ä½)
        let semantic_hash = Self::compute_text_hash_32(text);
        fp |= (semantic_hash as u64) & Self::MASK_SEMANTIC;

        // 2. æ—¶é—´åŒº [32-47] (16ä½) - ä»…ä¿ç•™æ—¶é—´
        if timestamp > 0 {
            let t_hash = Self::compute_temporal_hash(timestamp);
            fp |= ((t_hash as u64) << 32) & Self::MASK_TEMPORAL;
        }

        // 3. æƒ…æ„ŸåŒº [48-55] (8ä½)
        fp |= ((emotion_val as u64) << 48) & Self::MASK_AFFECTIVE;

        // 4. ç±»å‹åŒº [56-63] (8ä½)
        fp |= ((type_val as u64) << 56) & Self::MASK_TYPE;

        fp
    }

    /// é’ˆå¯¹æŸ¥è¯¢å­—ç¬¦ä¸²çš„æ™ºèƒ½æŒ‡çº¹ç”Ÿæˆ (å¢å¼ºçš„æ—¶é—´æ„ŸçŸ¥)
    /// ref_time: å¤–éƒ¨ä¼ å…¥çš„å‚è€ƒæ—¶é—´æˆ³ï¼ˆç°å®æ—¶é—´æˆ–å™äº‹æ—¶é—´ï¼‰ï¼Œç”¨äºè§£æç›¸å¯¹æ—¶é—´
    pub fn compute_for_query(query: &str, ref_time: u64) -> u64 {
        let mut timestamp = 0u64;
        let mut type_val = Self::TYPE_UNKNOWN;

        let query_lower = query.to_lowercase();

        // --- 1. ç›¸å¯¹æ—¶é—´è§£æ (ç›¸å¯¹æ—¶é—´åˆ†è¾¨ç‡) ---
        // åªæœ‰å½“ ref_time æœ‰æ•ˆ (>0) æ—¶æ‰å¯ç”¨ç›¸å¯¹æ—¶é—´è§£æ
        if ref_time > 0 {
            // 0. ä»Šå¤©/ä»Šæ—¥/æ­¤åˆ» (å½“å‰)
            if query_lower.contains("ä»Šå¤©") || query_lower.contains("ä»Šæ—¥") || query_lower.contains("today") || 
               query_lower.contains("now") || query_lower.contains("æ­¤åˆ»") || query_lower.contains("å½“å‰") {
                timestamp = ref_time;
            }
            // 1. æ˜¨å¤©/æ˜¨æ—¥ (1å¤©å‰)
            else if query_lower.contains("æ˜¨å¤©") || query_lower.contains("æ˜¨æ—¥") || query_lower.contains("yesterday") {
                timestamp = ref_time.saturating_sub(86400);
            }
            // 2. å‰å¤©/å‰æ—¥ (2å¤©å‰)
            else if query_lower.contains("å‰å¤©") || query_lower.contains("å‰æ—¥") {
                timestamp = ref_time.saturating_sub(172800);
            }
            // 3. å¤§å‰å¤© (3å¤©å‰)
            else if query_lower.contains("å¤§å‰å¤©") {
                timestamp = ref_time.saturating_sub(259200);
            }
            // 4. å‰å‡ å¤©/æœ€è¿‘ (çº¦3å¤©å‰) - æ¨¡ç³ŠåŒ¹é…
            else if query_lower.contains("å‰å‡ å¤©") || query_lower.contains("æœ€è¿‘") || query_lower.contains("recently") {
                timestamp = ref_time.saturating_sub(259200);
            }
            // 5. ä¸Šå‘¨/ä¸Šæ˜ŸæœŸ (7å¤©å‰)
            else if query_lower.contains("ä¸Šå‘¨") || query_lower.contains("last week") {
                timestamp = ref_time.saturating_sub(604800);
            }
            // 6. ä¸Šä¸ªæœˆ/ä¸Šæœˆ (30å¤©å‰)
            else if query_lower.contains("ä¸Šä¸ªæœˆ") || query_lower.contains("ä¸Šæœˆ") || query_lower.contains("last month") {
                timestamp = ref_time.saturating_sub(2592000);
            }
            // 7. å»å¹´ (365å¤©å‰)
            else if query_lower.contains("å»å¹´") || query_lower.contains("last year") {
                timestamp = ref_time.saturating_sub(31536000); 
            }
            // 8. å‰å¹´ (2å¹´å‰)
            else if query_lower.contains("å‰å¹´") {
                timestamp = ref_time.saturating_sub(63072000); 
            }
            // 9. åˆšæ‰/åˆšåˆš (åˆšæ‰ - 1åˆ†é’Ÿå‰)
            else if query_lower.contains("åˆšæ‰") || query_lower.contains("åˆšåˆš") || query_lower.contains("just now") {
                timestamp = ref_time.saturating_sub(60); 
            }
            // 10. æ—©ä¸Š/ä¸Šåˆ (æ—©æ™¨ - å‡è®¾å½“å¤©çš„ 9:00 AM)
            // è¿™æ˜¯ä¸€ä¸ªç²—ç•¥çš„é”šç‚¹ï¼Œå¦‚æœ ref_time å·²ç»æ˜¯å½“å¤©ï¼Œæˆ‘ä»¬å…¶å®åªéœ€è¦å½“å¤©çš„æ—¥æœŸéƒ¨åˆ†
            // ä½†ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œæš‚æ—¶æŒ‡å‘ ref_time (å½“å¤©)
            else if query_lower.contains("æ—©ä¸Š") || query_lower.contains("ä¸Šåˆ") || query_lower.contains("morning") {
                 timestamp = ref_time; 
            }
        }

        // --- 2. ç»å¯¹æ—¶é—´è§£æ (ç»å¯¹æ—¶é—´å›é€€) ---
        // åªæœ‰åœ¨ç›¸å¯¹æ—¶é—´æœªå‘½ä¸­æ—¶æ‰å°è¯•ç»å¯¹å¹´ä»½åŒ¹é…
        if timestamp == 0 {
            if query_lower.contains("2024") { timestamp = 1704067200; } // 2024-01-01
            if query_lower.contains("2025") { timestamp = 1735689600; } // 2025-01-01
            if query_lower.contains("2026") { timestamp = 1767225600; } // 2026-01-01
        }
        
        // æ¨¡æ‹Ÿæƒ…æ„Ÿæå– (Plutchik æƒ…æ„Ÿè½®)
        let emotion = Self::extract_emotion(&query_lower);

        // æ¨¡æ‹Ÿç±»å‹æ¨æ–­

        if query_lower.contains("pero") || query_lower.contains("ç”¨æˆ·") || query_lower.contains("å¥³å­©") {
            type_val = Self::TYPE_PERSON;
        } else if query_lower.contains("rust") || query_lower.contains("ä»£ç ") || query_lower.contains("ç®—æ³•") {
            type_val = Self::TYPE_TECH;
        } else if query_lower.contains("äº‹æƒ…") || query_lower.contains("å‘ç”Ÿ") {
            type_val = Self::TYPE_EVENT;
        } else if query_lower.contains("è´è¶ç»“") || query_lower.contains("é”®ç›˜") {
            type_val = Self::TYPE_OBJECT;
        }

        Self::compute_multimodal(&query_lower, timestamp, emotion, type_val)
    }

    fn get_emotion_keywords() -> &'static [(u8, &'static [&'static str])] {
        &[
            (Self::EMOTION_JOY, &[
                "å¼€å¿ƒ", "æ¬£æ…°", "æ£’", "æˆåŠŸ", "å¿«ä¹", "å¹¸ç¦", "é«˜å…´", "å–œæ‚¦",
                "å…´å¥‹", "çˆ½", "nice", "happy", "good", "great", "æ»¡æ„", "èˆ’æœ", 
                "èµ", "å®Œç¾", "ä¼˜ç§€", "åº†ç¥", "å“ˆå“ˆ", "lol", "awesome", "perfect", 
                "satisfied", "enjoy", "love", "å–œæ¬¢", "çˆ±", "æ»¡è¶³", "å¾—æ„", "ç‹‚å–œ",
                "luck", "win", "yeah", "é…·", "cool", "fun", "funny", "glad", 
                "pleased", "delight", "çˆ½ç¿»", "ä¹", "best", "wonderful"
            ]),
            (Self::EMOTION_SHY, &[ // ä¿¡ä»»/æ¥çº³
                "å®³ç¾", "ä¸å¥½æ„æ€", "è„¸çº¢", "è°¢è°¢", "æ„Ÿè°¢", "ä¿¡ä»»", "ä¾é ",
                "æŠ±æ­‰", "ä¾èµ–", "ç›¸ä¿¡", "æ•¬ä½©", "è®¤åŒ", "support", "trust", 
                "believe", "thanks", "agree", "accept", "admire", "å¿ è¯š", "è€å®",
                "å¯é ", "é è°±", "å®åœ¨", "çœŸè¯š", "å¦è¯š", "honest", "loyal", "faith",
                "true", "real", "safe", "secure", "respect", "appreciate"
            ]),
            (Self::EMOTION_FEAR, &[
                "å®³æ€•", "æ‹…å¿ƒ", "ç„¦è™‘", "ææƒ§", "ç´§å¼ ", "æ…Œ", "å“",
                "ææ€–", "å“äºº", "æ²¡åº•", "å¿å¿‘", "ä¸å®‰", "å±æœº", "é£é™©",
                "afraid", "scared", "worry", "nervous", "panic", "risk",
                "æƒŠæ…Œ", "èƒ†æ€¯", "ç•æƒ§", "alarm", "dread", "terror", "æ€•", "æ‚š",
                "æå¿ƒåŠèƒ†", "danger", "threat", "horror", "anxiety"
            ]),
            (Self::EMOTION_SURPRISE, &[
                "æ²¡æƒ³åˆ°", "ç«Ÿç„¶", "æƒŠè®¶", "éœ‡æƒŠ", "å§æ§½", "ç‰›é€¼", "å“‡",
                "å±…ç„¶", "æ„å¤–", "å¥‡è¿¹", "ç¥å¥‡", "amazing", "wow", "omg", 
                "surprise", "shock", "incredible", "unbelievable", "çŒä¸åŠé˜²",
                "æ„£ä½", "startle", "astonish", "æƒŠå‘†", "å‚»çœ¼", "æªæ‰‹ä¸åŠ",
                "wonder", "stun", "sudden", "unexpected"
            ]),
            (Self::EMOTION_SADNESS, &[
                "éš¾è¿‡", "ä½è½", "å¤±æœ›", "é—æ†¾", "ä¼¤å¿ƒ", "ç—›è‹¦", "æ‚²ä¼¤", "å“­",
                "æ³ª", "å¯æƒœ", "æŠ‘éƒ", "æ²®ä¸§", "å­¤ç‹¬", "æƒ¨", "å®Œè›‹", "å¿ƒç¢",
                "depressed", "sad", "sorry", "miss", "fail", "lost", "lonely",
                "å“€ä¼¤", "å‡„å‡‰", "è‹¦æ¼", "grief", "mourn", "upset", "ç—›", "éƒé—·",
                "å¿ƒé…¸", "hurt", "cry", "weep", "pity", "heartbroken"
            ]),
            (Self::EMOTION_DISGUST, &[
                "è®¨åŒ", "ä¸å–œæ¬¢", "çƒ‚", "æ¶å¿ƒ", "çƒ¦", "æ»š", "åƒåœ¾", "å·®åŠ²",
                "æ— è¯­", "é„™è§†", "æ¶åŠ£", "ä¸‘é™‹", "shit", "hate", "dislike", 
                "suck", "bad", "nasty", "awful", "boring", "åæ„Ÿ", "é„™å¤·",
                "å”¾å¼ƒ", "revulsion", "loathe", "å‘¸", "æ»šè›‹", "åºŸç‰©", "trash",
                "garbage", "gross", "yuck", "sick"
            ]),
            (Self::EMOTION_ANGER, &[
                "ç”Ÿæ°”", "æ¼ç«", "ä¸çˆ½", "æ„¤æ€’", "æ€’", "æ¨", "æ°”æ­»",
                "æš´èº", "å¦ˆçš„", "é ", "æŠ•è¯‰", "furious", "mad", "angry", 
                "rage", "fuck", "damn", "ç«å¤§", "å‘é£™", "irritate", "resent",
                "outrage", "æ°”ç‚¸", "æ‰¾æ­»", "é—­å˜´", "shut up", "piss off", "annoy"
            ]),
            (Self::EMOTION_ANTICIPATION, &[
                "æœŸå¾…", "æ„¿æ™¯", "æœªæ¥", "è§„åˆ’", "å¸Œæœ›", "æƒ³è¦", "ç›¼æœ›", "å‡†å¤‡",
                "è®¡åˆ’", "æ‰“ç®—", "ç›®æ ‡", "æ†§æ†¬", "ç­‰å¾…", "wait", "plan", "goal", 
                "hope", "expect", "ready", "wish", "æ¸´æœ›", "é¢„æ„Ÿ", "ç¥ˆç¥·",
                "ç¥æ„¿", "look forward", "desire", "pray", "dream", "seek"
            ]),
        ]
    }

    /// ä»æ–‡æœ¬ä¸­æå–æƒ…æ„Ÿ (Plutchik's Wheel)
    pub fn extract_emotion(text: &str) -> u8 {
        let mut emotion = 0u8;
        let text_lower = text.to_lowercase();
        
        for &(flag, keywords) in Self::get_emotion_keywords() {
            for &keyword in keywords {
                if text_lower.contains(keyword) {
                    emotion |= flag;
                    break;
                }
            }
        }

        emotion
    }

    /// ä¼ ç»Ÿçš„ SimHash è®¡ç®— (ä»…ç”¨äºè¯­ä¹‰åŒºï¼Œå‹ç¼©åˆ° 32 ä½)
    pub fn compute_text_hash_32(text: &str) -> u32 {
        let text_lower = text.to_lowercase();
        let mut v = [0i32; 32];
        
        for word in text_lower.split_whitespace() {
            Self::update_v_32(&mut v, word);
        }
        // å¤„ç†ä¸­æ–‡ç­‰æ— ç©ºæ ¼å­—ç¬¦
        for c in text_lower.chars() {
            let mut buf = [0u8; 4];
            let s = c.encode_utf8(&mut buf);
            Self::update_v_32(&mut v, s);
        }

        let mut finger_print = 0u32;
        for i in 0..32 {
            if v[i] > 0 {
                finger_print |= 1 << i;
            }
        }
        finger_print
    }

    /// å…¼å®¹æ—§ç‰ˆæ¥å£ (ä»…è®¡ç®—æ–‡æœ¬ï¼Œå…¶ä»–é»˜è®¤ä¸º 0)
    pub fn compute(text: &str) -> u64 {
        Self::compute_multimodal(text, 0, 0, 0)
    }

    fn update_v_32(v: &mut [i32; 32], token: &str) {
        let mut hasher = XxHash64::with_seed(0);
        token.hash(&mut hasher);
        let hash = hasher.finish();
        
        for i in 0..32 {
            let bit = (hash >> i) & 1;
            if bit == 1 {
                v[i] += 1;
            } else {
                v[i] -= 1;
            }
        }
    }

    fn compute_temporal_hash(timestamp: u64) -> u16 {
        // çº¯æ—¶é—´æˆ³å“ˆå¸Œ
        let mut hasher = XxHash64::with_seed(12345); // ç‹¬ç«‹ç§å­
        timestamp.hash(&mut hasher);
        let h = hasher.finish();
        (h & 0xFFFF) as u16
    }

    /// è®¡ç®—åŠ æƒæ±‰æ˜è·ç¦»ç›¸ä¼¼åº¦ (V2: æ”¯æŒåˆ†åŒºæƒé‡æ©ç )
    /// mask: ç”¨äºæŒ‡å®šåªå…³æ³¨å“ªäº›åŒºåŸŸ (ä¾‹å¦‚åªå…³æ³¨æ—¶ç©ºåŒº)
    pub fn similarity_weighted(a: u64, b: u64, mask: u64) -> f32 {
        let xor = (a ^ b) & mask;
        let dist = xor.count_ones();
        let total_bits = mask.count_ones();
        if total_bits == 0 { return 0.0; }
        1.0 - (dist as f32 / total_bits as f32)
    }
    
    /// åŸå§‹ç›¸ä¼¼åº¦æ¥å£
    pub fn similarity(a: u64, b: u64) -> f32 {
        // é»˜è®¤å…¨åŒºåŒ¹é…
        Self::similarity_weighted(a, b, 0xFFFFFFFFFFFFFFFF)
    }
}

// ============================================================================
// 2. æ ¸å¿ƒæ•°æ®ç»“æ„
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NodeType {
    Feature, // ç‰¹å¾é”šç‚¹ï¼ˆå…³é”®è¯ã€å®ä½“ï¼‰
    Event,   // äº‹ä»¶æ€»ç»“èŠ‚ç‚¹ï¼ˆè®°å¿†ä¸»ä½“ï¼‰
}

#[derive(Clone, Debug)]
pub struct GraphEdge {
    pub target_node_id: i64,
    pub connection_strength: u16,
    pub edge_type: u8, // V2: 0=å…³è”, 1=å› æœ, 2=é¡ºåº, 3=å¯¹æ¯”
}

pub struct Node {
    pub id: i64,
    pub node_type: NodeType,
    pub content: String,       // å¯¹äº Event æ˜¯æ€»ç»“ï¼Œå¯¹äº Feature æ˜¯å…³é”®è¯
    pub fingerprint: u64,      // è¯­ä¹‰æŒ‡çº¹
    
    // V2 æ–°å¢å­—æ®µ
    pub timestamp: u64,        // Unix æ—¶é—´æˆ³
    pub emotions: SmallVec<[u8; 8]>, // æƒ…æ„ŸçŸ¢é‡ (8ç»´)
    pub prev_event: Option<i64>,     // æ—¶åºå‰é©±
    pub next_event: Option<i64>,     // æ—¶åºåç»§
}

// ============================================================================
// 3. é«˜çº§å®éªŒå¼•æ“
// ============================================================================

pub struct ChaosStore {
    pub ids: Vec<i64>,
    pub fingerprints: Vec<ChaosFingerprint>,
    pub vectors: Vec<Vec<f16>>,
    pub id_to_index: AHashMap<i64, usize>,
}

impl ChaosStore {
    pub fn new() -> Self {
        Self {
            ids: Vec::new(),
            fingerprints: Vec::new(),
            vectors: Vec::new(),
            id_to_index: AHashMap::new(),
        }
    }

    pub fn add(&mut self, id: i64, fp: ChaosFingerprint, vec: Vec<f16>) {
        if !self.id_to_index.contains_key(&id) {
            let idx = self.ids.len();
            self.ids.push(id);
            self.fingerprints.push(fp);
            self.vectors.push(vec);
            self.id_to_index.insert(id, idx);
        }
    }
}

pub trait AsyncTaskInterface {
    fn schedule_maintenance(&self, context: &str);
}

pub struct MockAsyncTask;
impl AsyncTaskInterface for MockAsyncTask {
    fn schedule_maintenance(&self, _context: &str) {
        // Placeholder
    }
}

pub struct AdvancedEngine {
    pub nodes: AHashMap<i64, Node>,
    pub chaos_store: ChaosStore,
    pub graph: AHashMap<i64, SmallVec<[GraphEdge; 4]>>,
    
    // ç¬¬ä¸€å¥—æ•°æ®åº“ï¼šå®šä¹‰åº“ (Ontology)
    pub ontology_graph: AHashMap<i64, SmallVec<[GraphEdge; 4]>>,
    
    // æœç´¢è¾…åŠ©
    pub ac_matcher: Option<AhoCorasick>,
    pub feature_keywords: Vec<String>,
    pub keyword_to_node: AHashMap<String, i64>,
    
    // V2: æ€§èƒ½æ§åˆ¶
    pub in_degrees: AHashMap<i64, u32>, // é¢„è®¡ç®—å…¥åº¦
    
    // V2: æ—¶ç©ºç´¢å¼• (Temporal Index) - ç”¨äºå¿«é€Ÿå…±æŒ¯å¬å›
    pub temporal_index: AHashMap<u16, Vec<i64>>,
    
    // V2: æƒ…æ„Ÿç´¢å¼• (Affective Index) - ç”¨äºæƒ…æ„Ÿå…±æŒ¯
    pub affective_index: AHashMap<u8, Vec<i64>>,

    // V2: å¼‚æ­¥æ¥å£
    pub async_task: Box<dyn AsyncTaskInterface + Send + Sync>,

    // ç¬¬å››é˜¶æ®µ: Candle åµŒå…¥æ¨¡å‹
    pub embedding_model: Option<CandleModel>,
}

impl AdvancedEngine {
    pub fn new() -> Self {
        Self {
            nodes: AHashMap::new(),
            chaos_store: ChaosStore::new(),
            graph: AHashMap::new(),
            ontology_graph: AHashMap::new(),
            ac_matcher: None,
            feature_keywords: Vec::new(),
            keyword_to_node: AHashMap::new(),
            in_degrees: AHashMap::new(),
            temporal_index: AHashMap::new(),
            affective_index: AHashMap::new(),
            async_task: Box::new(MockAsyncTask),
            embedding_model: None,
        }
    }

    /// æ·»åŠ ç‰¹å¾èŠ‚ç‚¹
    pub fn add_feature(&mut self, id: i64, keyword: &str) {
        let keyword_lower = keyword.to_lowercase();
        
        // --- åœç”¨è¯ç¡¬è¿‡æ»¤ (åŒä¿é™©æœºåˆ¶) ---
        // åŒ…å«ä¸­è‹±æ–‡å¸¸è§çš„è™šè¯ã€ä»‹è¯ã€ä»£è¯ã€åŠ©åŠ¨è¯åŠè¿è¯
        let stopwords = [
            // ä¸­æ–‡è™šè¯
            "çš„", "æ˜¯", "äº†", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£", "éƒ½", "å’Œ", "å¹¶", "ä¸”",
            "ä¹Ÿ", "å°±", "ç€", "å§", "å—", "å‘¢", "å•Š", "å‘€", "å‘œ", "å“", "å“¼", "å‘¸", "å–½",
            // è‹±æ–‡ä»‹è¯
            "a", "an", "the", "about", "above", "across", "after", "against", "along", "among", "around", "at", 
            "before", "behind", "below", "beneath", "beside", "between", "beyond", "but", "by", "despite", "down", 
            "during", "except", "for", "from", "in", "inside", "into", "like", "near", "of", "off", "on", "onto", 
            "out", "outside", "over", "past", "since", "through", "throughout", "till", "to", "toward", "under", 
            "underneath", "until", "up", "upon", "with", "within", "without",
            // è‹±æ–‡ä»£è¯
            "i", "me", "my", "mine", "we", "us", "our", "ours", "you", "your", "yours", "he", "him", "his", 
            "she", "her", "hers", "it", "its", "they", "them", "their", "theirs", "this", "that", "these", "those", 
            "who", "whom", "whose", "which", "what", "each", "every", "either", "neither", "some", "any", "no", 
            "none", "both", "few", "many", "other", "another",
            // è‹±æ–‡åŠ©åŠ¨è¯
            "am", "is", "are", "was", "were", "be", "being", "been", "have", "has", "had", "do", "does", "did", 
            "shall", "will", "should", "would", "may", "might", "must", "can", "could",
            // è‹±æ–‡è¿è¯åŠå…¶ä»–
            "and", "or", "so", "nor", "yet", "although", "because", "unless", "while", "where", "when", "how", "whether"
        ];
        if stopwords.contains(&keyword_lower.as_str()) {
            return;
        }

        let node = Node {
            id,
            node_type: NodeType::Feature,
            content: keyword_lower.clone(),
            fingerprint: SimHash::compute(&keyword_lower),
            timestamp: 0,
            emotions: SmallVec::new(),
            prev_event: None,
            next_event: None,
        };
        self.nodes.insert(id, node);
        self.feature_keywords.push(keyword_lower.clone());
        self.keyword_to_node.insert(keyword_lower, id);
    }

    /// è¾…åŠ©ï¼šä»æ–‡æœ¬ä¸­æå–æ—¥æœŸå¹¶è½¬æ¢ä¸ºæ—¶é—´æˆ³ (YYYYå¹´MMæœˆDDæ—¥)
    fn extract_timestamp(text: &str) -> u64 {
        // ç®€æ˜“è§£æå™¨ï¼ŒæŸ¥æ‰¾ "20xxå¹´xxæœˆxxæ—¥"
        // é»˜è®¤åŸºå‡†æ—¶é—´ï¼š2023-01-01 (1672531200)
        let default_ts = 1672531200;
        
        // éå†æ‰€æœ‰ "å¹´" çš„å‡ºç°ä½ç½®
        for (year_idx, _) in text.match_indices("å¹´") {
            if year_idx >= 4 && text.is_char_boundary(year_idx - 4) {
                if let Ok(year) = text[year_idx-4..year_idx].parse::<i32>() {
                    let mut day = 1;
                    
                    let rest = &text[year_idx+3..]; // è·³è¿‡ "å¹´" (UTF-8 3å­—èŠ‚)
                    
                    // æŸ¥æ‰¾ "æœˆ"ï¼Œä¸”è·ç¦»ä¸åº”å¤ªè¿œ (æœ€å¤š 5å­—èŠ‚ï¼Œå®¹çº³ " 12" æˆ– "1")
                    if let Some(month_idx) = rest.find("æœˆ") {
                        if month_idx <= 5 {
                            let m_str = rest[..month_idx].trim();
                            if let Ok(month) = m_str.parse::<i32>() {
                                
                                let rest_day = &rest[month_idx+3..];
                                // æŸ¥æ‰¾ "æ—¥"ï¼Œè·ç¦»ä¹Ÿä¸åº”å¤ªè¿œ
                                if let Some(day_idx) = rest_day.find("æ—¥") {
                                    if day_idx <= 5 {
                                        let d_str = rest_day[..day_idx].trim();
                                        if let Ok(d) = d_str.parse::<i32>() {
                                            day = d;
                                        }
                                    }
                                }
                                
                                // ç®€å•è½¬ä¸º Unix æ—¶é—´æˆ³
                                let ts = (year as u64 - 1970) * 31536000 + (month as u64) * 2592000 + (day as u64) * 86400;
                                return ts;
                            }
                        }
                    }
                }
            }
        }
        default_ts
    }

    /// æ··æ²Œå‘é‡åŒ–æ¥å£ï¼šå°†æ–‡æœ¬è‡ªåŠ¨è½¬æ¢ä¸º 512 ç»´ f16 å‘é‡å’Œ 512-bit ChaosFingerprint æŒ‡çº¹
    pub fn calculate_chaos(&self, text: &str) -> Option<(ChaosFingerprint, Vec<f16>)> {
        let model = self.embedding_model.as_ref()?;
        
        let mut weighted_ranges = Vec::new();
        if let Some(matcher) = &self.ac_matcher {
            for mat in matcher.find_iter(&text.to_lowercase()) {
                weighted_ranges.push((mat.start(), mat.end(), 5.0));
            }
        }

        if let Some(vec_f32) = model.vectorize_weighted(text, &weighted_ranges) {
            let chaos_vector: Vec<f16> = vec_f32.iter().map(|&x| f16::from_f32(x)).collect();
            let chaos_fingerprint = StorageEngine::quantize_vector(&chaos_vector);
            Some((chaos_fingerprint, chaos_vector))
        } else {
            None
        }
    }

    /// æ·»åŠ äº‹ä»¶èŠ‚ç‚¹
    pub fn add_event(&mut self, id: i64, summary: &str, chaos_fp: Option<ChaosFingerprint>, chaos_vec: Option<Vec<f16>>) {
        // è‡ªåŠ¨æå–æ—¶é—´æˆ³
        let timestamp = Self::extract_timestamp(summary);

        // è‡ªåŠ¨æå–æƒ…æ„Ÿ (æ–°: è‡ªåŠ¨æƒ…æ„Ÿæå–)
        let emotion_val = SimHash::extract_emotion(summary);

        // V2: åœ¨å…¥åº“æ—¶è‡ªåŠ¨è¿›è¡Œæ—¶ç©º/æƒ…æ„Ÿç‰¹å¾æå– (è‡ªåŠ¨æ‰“æ ‡)
        // ä½¿ç”¨æå–åˆ°çš„ç»å¯¹æ—¶é—´æˆ³å’Œæƒ…æ„Ÿå€¼æ¥è®¡ç®—åˆå§‹æŒ‡çº¹
        let fingerprint = SimHash::compute_multimodal(summary, timestamp, emotion_val, 0);

        // V3 ç¬¬å››é˜¶æ®µ: è‡ªåŠ¨å‘é‡åŒ– (æ··æ²Œå‘é‡)
        let mut chaos_fingerprint = chaos_fp.unwrap_or(ChaosFingerprint::default());
        let mut chaos_vector = chaos_vec.unwrap_or_default();

        if chaos_fingerprint == ChaosFingerprint::default() && chaos_vector.is_empty() {
            if let Some((fp, vec)) = self.calculate_chaos(summary) {
                chaos_fingerprint = fp;
                chaos_vector = vec;
            }
        }
        
        // å¡«å……æƒ…æ„Ÿå‘é‡
        let mut emotions = SmallVec::new();
        for i in 0..8 {
            if (emotion_val & (1 << i)) != 0 {
                emotions.push(1 << i);
            }
        }
        
        let node = Node {
            id,
            node_type: NodeType::Event,
            content: summary.to_string(),
            fingerprint,
            timestamp, 
            emotions,
            prev_event: None,
            next_event: None,
        };
        self.nodes.insert(id, node);
        
        // SoA å­˜å‚¨
        if chaos_fingerprint != ChaosFingerprint::default() || !chaos_vector.is_empty() {
             self.chaos_store.add(id, chaos_fingerprint, chaos_vector);
        }

        // V2: æ›´æ–°å€’æ’ç´¢å¼• (Inverted Indexes) ç”¨äºå¿«é€Ÿå¬å›
        // 1. æ—¶ç©ºç´¢å¼•
        if (fingerprint & SimHash::MASK_TEMPORAL) != 0 {
            let st_hash = ((fingerprint & SimHash::MASK_TEMPORAL) >> 32) as u16;
            self.temporal_index.entry(st_hash).or_default().push(id);
        }

        // 2. æƒ…æ„Ÿç´¢å¼•
        if (fingerprint & SimHash::MASK_AFFECTIVE) != 0 {
            let emotion_hash = ((fingerprint & SimHash::MASK_AFFECTIVE) >> 48) as u8;
            for i in 0..8 {
                if (emotion_hash & (1 << i)) != 0 {
                    self.affective_index.entry(1 << i).or_default().push(id);
                }
            }
        }
    }

    /// å»ºç«‹å…³è” (V2: å¢åŠ é‡å¤è¾¹æ£€æµ‹ä¸å¼ºåº¦æ›´æ–°é€»è¾‘)
    pub fn add_edge(&mut self, src: i64, tgt: i64, weight: f32) {
        let quantized = (weight.clamp(0.0, 1.0) * 65535.0) as u16;
        let edges = self.graph.entry(src).or_default();
        
        if let Some(edge) = edges.iter_mut().find(|e| e.target_node_id == tgt) {
            // å¦‚æœè¾¹å·²å­˜åœ¨ï¼Œæ›´æ–°ä¸ºè¾ƒå¤§çš„å¼ºåº¦å€¼ (æ¨¡æ‹Ÿè®°å¿†å¢å¼º)
            if quantized > edge.connection_strength {
                edge.connection_strength = quantized;
            }
        } else {
            edges.push(GraphEdge {
                target_node_id: tgt,
                connection_strength: quantized,
                edge_type: 0,
            });
        }
    }

    /// æ·»åŠ å®šä¹‰åº“å…³è” (ç¬¬ä¸€å¥—æ•°æ®åº“)
    /// relation_type: "equality" | "inhibition" | "representation"
    pub fn maintain_ontology(&mut self, source: &str, target: &str, relation_type: &str, strength: f32) {
        println!("ğŸ¤– [LLM Maintenance] å‘ç°æ–°å…³è”: {} -> {} (type: {}, strength: {})", 
                 source, target, relation_type, strength);
        
        let src_id = self.get_or_create_feature(source);
        let tgt_id = self.get_or_create_feature(target);
        
        let strength_u16 = (strength * 65535.0) as u16;
        
        // ç¡®å®šè¾¹ç±»å‹ (ç®€åŒ–ä¸ºä¸‰ç§æ ¸å¿ƒé€»è¾‘)
        let edge_type = match relation_type.to_lowercase().as_str() {
            "equality" | "equal" => 1, // SimHash::EDGE_EQUALITY (æš‚æ—¶ç¡¬ç¼–ç ä»¥ä¿®å¤ç¼–è¯‘é”™è¯¯)
            "inhibition" | "conflict" => 255, // SimHash::EDGE_INHIBITION
            _ => 0, // SimHash::EDGE_REPRESENTATION
        };

        // å¤„ç†æ­£å‘è¾¹
        {
            let edges = self.ontology_graph.entry(src_id).or_default();
            if let Some(edge) = edges.iter_mut().find(|e| e.target_node_id == tgt_id) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ– (Hebbian Learning)
                edge.connection_strength = edge.connection_strength.saturating_add(strength_u16 / 2).max(strength_u16);
                // æ›´æ–°ç±»å‹
                edge.edge_type = edge_type;
            } else {
                edges.push(GraphEdge {
                    target_node_id: tgt_id,
                    connection_strength: strength_u16,
                    edge_type,
                });
            }
        }
        
        // å¤„ç†åå‘è¾¹
        // 1. Equality (Type 1): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º A==B ä¸” B==A
        // 2. Inhibition (Type 255): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º Aäº’æ–¥B ä¸” Bäº’æ–¥A
        // 3. Representation (Type 0): é»˜è®¤å•å‘ (Directed)ï¼Œå› ä¸º"çœ‹åˆ°Bæƒ³åˆ°A"ä¸ä»£è¡¨"çœ‹åˆ°Aä¸€å®šæƒ³åˆ°B"
        //    (é™¤éä¸šåŠ¡å±‚æ˜¾å¼è¦æ±‚åŒå‘ï¼Œå¦åˆ™åº•å±‚åªå­˜å•å‘)
        if edge_type == 1 || edge_type == 255 {
            let rev_edges = self.ontology_graph.entry(tgt_id).or_default();
            if let Some(edge) = rev_edges.iter_mut().find(|e| e.target_node_id == src_id) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ–
                edge.connection_strength = edge.connection_strength.saturating_add(strength_u16 / 2).max(strength_u16);
                edge.edge_type = edge_type;
            } else {
                rev_edges.push(GraphEdge {
                    target_node_id: src_id,
                    connection_strength: strength_u16,
                    edge_type,
                });
            }
        }
    }

    // ========================================================================
    // åŠ¨æ€å‰ªæ (LTD: Long-Term Depression)
    // ========================================================================

    /// æ‰§è¡Œå…¨å±€è¡°å‡ä¸ç‰©ç†å‰ªæ
    /// decay_rate: è¡°å‡æ¯”ç‡ (0.0 - 1.0)ï¼Œå»ºè®® 0.95
    /// threshold: å‰ªæé˜ˆå€¼ (0 - 65535)ï¼Œå»ºè®® 3276 (0.05)
    pub fn apply_global_decay_and_pruning(&mut self, decay_rate: f32, threshold: u16) -> usize {
        let mut pruned_count = 0;
        
        // éå†æ•´ä¸ª Ontology å›¾è°±
        for edges in self.ontology_graph.values_mut() {
            // 1. å…¨å±€ç†µå¢ (Entropy Increase)
            for edge in edges.iter_mut() {
                let current = edge.connection_strength as f32;
                edge.connection_strength = (current * decay_rate) as u16;
            }
            
            // 2. ç‰©ç†æ–­è£‚ (Pruning)
            let before_len = edges.len();
            edges.retain(|e| e.connection_strength > threshold);
            let after_len = edges.len();
            
            pruned_count += before_len - after_len;
        }
        
        if pruned_count > 0 {
            println!("[PEDSA Memory] Pruning executed: {} synapses disconnected.", pruned_count);
        }
        
        pruned_count
    }

    fn get_or_create_feature(&mut self, word: &str) -> i64 {
        let word_lower = word.to_lowercase();
        
        // åœç”¨è¯æ£€æŸ¥ (åŒæ­¥ add_feature ä¸­çš„åˆ—è¡¨)
        let stopwords = [
            // ä¸­æ–‡è™šè¯
            "çš„", "æ˜¯", "äº†", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£", "éƒ½", "å’Œ", "å¹¶", "ä¸”",
            "ä¹Ÿ", "å°±", "ç€", "å§", "å—", "å‘¢", "å•Š", "å‘€", "å‘œ", "å“", "å“¼", "å‘¸", "å–½",
            // è‹±è¯­ä»‹è¯
            "a", "an", "the", "about", "above", "across", "after", "against", "along", "among", "around", "at", 
            "before", "behind", "below", "beneath", "beside", "between", "beyond", "but", "by", "despite", "down", 
            "during", "except", "for", "from", "in", "inside", "into", "like", "near", "of", "off", "on", "onto", 
            "out", "outside", "over", "past", "since", "through", "throughout", "till", "to", "toward", "under", 
            "underneath", "until", "up", "upon", "with", "within", "without",
            // è‹±è¯­ä»£è¯
            "i", "me", "my", "mine", "we", "us", "our", "ours", "you", "your", "yours", "he", "him", "his", 
            "she", "her", "hers", "it", "its", "they", "them", "their", "theirs", "this", "that", "these", "those", 
            "who", "whom", "whose", "which", "what", "each", "every", "either", "neither", "some", "any", "no", 
            "none", "both", "few", "many", "other", "another",
            // è‹±è¯­åŠ©åŠ¨è¯
            "am", "is", "are", "was", "were", "be", "being", "been", "have", "has", "had", "do", "does", "did", 
            "shall", "will", "should", "would", "may", "might", "must", "can", "could",
            // è‹±è¯­è¿è¯åŠå…¶ä»–
            "and", "or", "so", "nor", "yet", "although", "because", "unless", "while", "where", "when", "how", "whether"
        ];
        if stopwords.contains(&word_lower.as_str()) {
            return -1; // è¿”å›éæ³• ID è¡¨ç¤ºè¯¥è¯è¢«å±è”½
        }

        if let Some(&id) = self.keyword_to_node.get(&word_lower) {
            id
        } else {
            let mut s = XxHash64::with_seed(0);
            word_lower.hash(&mut s);
            let id = (s.finish() as i64).abs();
            self.add_feature(id, &word_lower);
            id
        }
    }

    /// å»ºç«‹åŒå‘æ—¶åºé“¾è¡¨ (Temporal Backbone)
    pub fn build_temporal_backbone(&mut self) {
        println!("â³ æ­£åœ¨æ„å»ºæ—¶åºè„Šæ¢ (Temporal Backbone)...");
        
        // 1. æ”¶é›†æ‰€æœ‰ Event èŠ‚ç‚¹å¹¶æŒ‰æ—¶é—´æˆ³æ’åº
        let mut events: Vec<(i64, u64)> = self.nodes.values()
            .filter(|n| n.node_type == NodeType::Event)
            .map(|n| (n.id, n.timestamp))
            .collect();
        
        // å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œæš‚æ—¶ç”¨ ID æ¨¡æ‹Ÿé¡ºåºï¼ˆä»…ä¾›æµ‹è¯•ï¼‰
        // åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œtimestamp åº”è¯¥æ˜¯å¿…å¡«çš„
        events.sort_by(|a, b| {
            if a.1 != b.1 {
                a.1.cmp(&b.1)
            } else {
                a.0.cmp(&b.0) // æ—¶é—´æˆ³ç›¸åŒåˆ™æŒ‰ ID æ’åº
            }
        });

        // 2. ä¸²è”åŒå‘é“¾è¡¨
        for i in 0..events.len() {
            let (curr_id, _) = events[i];
            
            if i > 0 {
                let (prev_id, _) = events[i-1];
                if let Some(node) = self.nodes.get_mut(&curr_id) {
                    node.prev_event = Some(prev_id);
                }
            }
            
            if i < events.len() - 1 {
                let (next_id, _) = events[i+1];
                if let Some(node) = self.nodes.get_mut(&curr_id) {
                    node.next_event = Some(next_id);
                }
            }
        }
        println!("âœ… æ—¶åºè„Šæ¢æ„å»ºå®Œæˆï¼Œå·²ä¸²è” {} ä¸ªäº‹ä»¶èŠ‚ç‚¹ã€‚", events.len());
    }

    /// åŠ è½½æ ‡å‡†æµ‹è¯•æ•°æ®é›†
    pub fn load_standard_data(&mut self) {
        println!("ğŸ“¦ æ­£åœ¨æ³¨å…¥ç¡¬æ ¸æµ‹è¯•æ•°æ®...");
        let mut all_events = Vec::new();
        let mut all_edges = Vec::new();

        let (e1, d1) = get_tech_domain_data();
        all_events.extend(e1); all_edges.extend(d1);

        let (e2, d2) = get_social_domain_data();
        all_events.extend(e2); all_edges.extend(d2);

        let (e3, d3) = get_history_domain_data();
        all_events.extend(e3); all_edges.extend(d3);

        let (e4, d4) = get_value_domain_data();
        all_events.extend(e4); all_edges.extend(d4);

        let (e5, d5) = get_daily_domain_data();
        all_events.extend(e5); all_edges.extend(d5);

        let (e6, d6) = get_timeline_domain_data();
        all_events.extend(e6); all_edges.extend(d6);
        
        // æ³¨å…¥èŠ‚ç‚¹ä¸ç‰¹å¾
        for ev in all_events {
            self.add_event(ev.id, ev.summary, ev.chaos_fingerprint, ev.chaos_vector);
            for feature in ev.features {
                let feature_lower = feature.to_lowercase();
                let mut s = XxHash64::with_seed(0);
                feature_lower.hash(&mut s);
                let feat_id = (s.finish() as i64).abs();
                
                self.add_feature(feat_id, &feature_lower);
                self.add_edge(feat_id, ev.id, 1.0);
            }
        }

        // 2. åŠ è½½å®šä¹‰åº“æ•°æ® (Ontology)
        println!("ğŸ“š æ­£åœ¨æ³¨å…¥å®šä¹‰åº“ (Ontology) æ•°æ®...");
        let ontology_edges = get_ontology_data();
        for edge in ontology_edges {
            // V3.5: ä½¿ç”¨å¸¦å…³ç³»ç±»å‹çš„ maintain_ontology
            let relation_type = if edge.is_equality {
                "equality"
            } else if edge.is_inhibition {
                "inhibition"
            } else {
                "representation"
            };
            self.maintain_ontology(edge.src, edge.tgt, relation_type, edge.weight);
        }

        // 3. æ³¨å…¥é€»è¾‘è¾¹
        for edge in all_edges {
            self.add_edge(edge.src, edge.tgt, edge.weight);
        }

        // 4. æ‰‹åŠ¨å»ºç«‹ä¸€äº›è·¨é¢†åŸŸçš„â€œéšç§˜å…³è”â€
        self.add_edge(205, 100, 0.6); // 1k star (205) ä¸ PeroCore é‡æ„ (100)
        self.add_edge(200, 302, 0.4); // é¢è¯•è¢«å¥—æ–¹æ¡ˆ (200) ä¸ PEASE ç®—æ³•çµæ„Ÿ (302)

        // V2: æ„å»ºæ—¶åºè„Šæ¢
        self.build_temporal_backbone();
    }

    /// ç¼–è¯‘ AC è‡ªåŠ¨æœº
    pub fn compile(&mut self) {
        // åªå¯¹ Feature èŠ‚ç‚¹ç¼–è¯‘ AC è‡ªåŠ¨æœº
        let mut keywords: Vec<_> = self.nodes.values()
            .filter(|n| n.node_type == NodeType::Feature)
            .map(|n| n.content.clone())
            .collect();
        
        // V2: å…³é”®ä¼˜åŒ– - æŒ‰é•¿åº¦é™åºæ’åºï¼Œç¡®ä¿ä¼˜å…ˆåŒ¹é…é•¿è¯ (å¦‚ "åˆ†å¸ƒå¼ç¼–è¯‘" ä¼˜äº "åˆ†å¸ƒå¼")
        keywords.sort_by(|a, b| b.len().cmp(&a.len()));

        if !keywords.is_empty() {
            self.ac_matcher = Some(AhoCorasickBuilder::new()
                .match_kind(MatchKind::LeftmostLongest)
                .build(&keywords)
                .unwrap());
            self.feature_keywords = keywords;
        }

        // V2: è®¡ç®—èŠ‚ç‚¹å…¥åº¦ (In-degree) ä»¥ç”¨äºåå‘æŠ‘åˆ¶
        self.in_degrees.clear();
        // ç»Ÿè®¡ Memory Graph
        for edges in self.graph.values() {
            for edge in edges {
                *self.in_degrees.entry(edge.target_node_id).or_default() += 1;
            }
        }
        // ç»Ÿè®¡ Ontology Graph
        for edges in self.ontology_graph.values() {
            for edge in edges {
                *self.in_degrees.entry(edge.target_node_id).or_default() += 1;
            }
        }

        // V2: æ„å»ºæ—¶ç©ºç´¢å¼• (Spatio-Temporal Index) ä¸ æƒ…æ„Ÿç´¢å¼• (Affective Index)
        self.temporal_index.clear();
        self.affective_index.clear();

        for node in self.nodes.values() {
            if node.node_type == NodeType::Event {
                // æ—¶ç©ºç´¢å¼•
                let st_hash = ((node.fingerprint & SimHash::MASK_TEMPORAL) >> 32) as u16;
                if st_hash != 0 {
                    self.temporal_index.entry(st_hash).or_default().push(node.id);
                }

                // æƒ…æ„Ÿç´¢å¼•
                let emotion_hash = ((node.fingerprint & SimHash::MASK_AFFECTIVE) >> 48) as u8;
                if emotion_hash != 0 {
                    // å¯¹äºæ¯ä¸ªè®¾ç½®äº†çš„ä½ï¼Œéƒ½åŠ å…¥åˆ°å¯¹åº”çš„ç´¢å¼•æ¡¶ä¸­ (æ”¯æŒæ··åˆæƒ…æ„Ÿ)
                    for i in 0..8 {
                        if (emotion_hash & (1 << i)) != 0 {
                            self.affective_index.entry(1 << i).or_default().push(node.id);
                        }
                    }
                }
            }
        }

        println!("ğŸš€ å¼•æ“ç¼–è¯‘å®Œæˆï¼š{} ä¸ªç‰¹å¾é”šç‚¹, {} ä¸ªæ€»èŠ‚ç‚¹, {} ä¸ªæ—¶ç©ºæ¡¶, {} ä¸ªæƒ…æ„Ÿç»´åº¦", 
            self.feature_keywords.len(), self.nodes.len(), self.temporal_index.len(), self.affective_index.len());
    }

    /// å¤§è§„æ¨¡å‹åŠ›æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
    pub fn load_million_test_data(&mut self, node_count: usize) {
        println!("ğŸ—ï¸ æ­£åœ¨ç”Ÿæˆ {} çº§å¤§è§„æ¨¡åˆæˆæ•°æ®...", node_count);
        let start = Instant::now();

        // é¢„åˆ†é…å†…å­˜ä»¥åº”å¯¹åƒä¸‡çº§åˆ«çš„å‹åŠ›ï¼Œå‡å°‘é‡æ–°åˆ†é…å¯¼è‡´çš„æ€§èƒ½æŠ–åŠ¨å’Œå†…å­˜ç¢ç‰‡
        self.nodes.reserve(node_count + 50000);
        self.graph.reserve(node_count + 50000);
        self.keyword_to_node.reserve(50000);
        self.feature_keywords.reserve(50000);
        
        // 1. ç”Ÿæˆç‰¹å¾èŠ‚ç‚¹ (å›ºå®š 50,000 ä¸ªï¼Œæ›´ç¬¦åˆçœŸå® Ontology è§„æ¨¡)
        let feature_count = 50_000;
        for i in 0..feature_count {
            let id = i as i64 + 1_000_000_000;
            let kw = format!("feat_{}", i);
            self.add_feature(id, &kw);
        }

        // 2. ç”Ÿæˆäº‹ä»¶èŠ‚ç‚¹
        let event_count = node_count;
        for i in 0..event_count {
            let id = i as i64 + 2_000_000_000;
            let summary = format!("è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„äº‹ä»¶æ€»ç»“èŠ‚ç‚¹ï¼Œç¼–å·ä¸º {}ï¼Œç”¨äºè¿›è¡Œè§„æ¨¡å‹åŠ›æµ‹è¯•ã€‚PEDSA ç®—æ³•åº”å½“åœ¨è¿™ç§è§„æ¨¡ä¸‹ä¾ç„¶ä¿æŒæé«˜çš„æ£€ç´¢æ•ˆç‡ã€‚", i);
            self.add_event(id, &summary, None, None);
            
            // æ¯ä¸ªäº‹ä»¶éšæœºå…³è” 1-3 ä¸ªç‰¹å¾
            let feat_idx = i % feature_count;
            let feat_id = feat_idx as i64 + 1_000_000_000;
            self.add_edge(feat_id, id, 1.0);
            
            if i % 2 == 0 {
                let feat_id_2 = (i * 7 % feature_count) as i64 + 1_000_000_000;
                self.add_edge(feat_id_2, id, 0.8);
            }
        }

        println!("âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶: {:?}", start.elapsed());
    }

    /// æ‰§è¡Œå¤šçº§æ£€ç´¢ (V2: å¢åŠ èƒ½é‡æ§åˆ¶æœºåˆ¶ + åˆ†åŒºæ—¶ç©ºå…±æŒ¯)
    /// ç¬¬å››é˜¶æ®µï¼šåŒè½¨æ£€ç´¢ï¼ˆç†æ€§ + æ··æ²Œï¼‰
    /// 
    /// # å‚æ•°
    /// * `query` - æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
    /// * `ref_time` - ç”¨äºç›¸å¯¹æ—¶é—´è§£æçš„å‚è€ƒæ—¶é—´æˆ³ã€‚
    /// * `chaos_level` - 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
    ///   - 0.0: çº¯ç†æ€§æ£€ç´¢ï¼ˆç¡®å®šæ€§ï¼‰ã€‚
    ///   - 1.0: çº¯æ··æ²Œæ£€ç´¢ï¼ˆé«˜éšæœºæ€§/åˆ›é€ æ€§ï¼‰ã€‚
    ///   - ä¸­é—´å€¼åˆ™æ··åˆä¸¤è€…çš„å¾—åˆ†ã€‚
    pub fn retrieve(&self, query: &str, ref_time: u64, chaos_level: f32) -> Vec<(i64, f32)> {
        let mut activated_keywords = AHashMap::new();
        let query_lower = query.to_lowercase();
        // V2: ä½¿ç”¨æ™ºèƒ½æŒ‡çº¹ç”Ÿæˆï¼Œæå–æ—¶ç©º/æƒ…æ„Ÿç‰¹å¾
        // ä¼ å…¥ ref_time ä»¥æ”¯æŒç›¸å¯¹æ—¶é—´è§£æ
        let query_fp = SimHash::compute_for_query(&query_lower, ref_time);

        // --- Step 1: ç‰¹å¾å…±æŒ¯ (AC Matcher) - æå¿« ---
        if let Some(matcher) = &self.ac_matcher {
            for mat in matcher.find_iter(&query_lower) {
                let kw = &self.feature_keywords[mat.pattern()];
                if let Some(&node_id) = self.keyword_to_node.get(kw) {
                    activated_keywords.insert(node_id, 1.0);
                }
            }
        }

        // --- Step 1.5: æ—¶é—´å…±æŒ¯ (Temporal Resonance) ---
        // å¦‚æœ Query åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œç›´æ¥ä»ç´¢å¼•ä¸­å¬å›å€™é€‰èŠ‚ç‚¹ (ç»•è¿‡è¯­ä¹‰åŒ¹é…)
        if (query_fp & SimHash::MASK_TEMPORAL) != 0 {
            let st_hash = ((query_fp & SimHash::MASK_TEMPORAL) >> 32) as u16;
            if let Some(candidates) = self.temporal_index.get(&st_hash) {
                // å°†è¿™äº›å€™é€‰èŠ‚ç‚¹åŠ å…¥åˆå§‹æ¿€æ´»é›†åˆ
                // æ³¨æ„ï¼šè¿™äº›é€šå¸¸æ˜¯ Event èŠ‚ç‚¹ï¼Œå®ƒä»¬å°†ç›´æ¥ä½œä¸ºç§å­è¿›å…¥åç»­æµç¨‹
                for &id in candidates {
                    let entry = activated_keywords.entry(id).or_insert(0.0);
                    // åˆå§‹å…±æŒ¯èƒ½é‡è®¾ä¸º 0.6 (ä½äºå®Œå…¨åŒ¹é…çš„ 1.0)
                    if *entry < 0.6 { *entry = 0.6; }
                }
            }
        }

        // --- Step 1.6: æƒ…æ„Ÿå…±æŒ¯ (Affective Resonance) ---
        // å¦‚æœ Query åŒ…å«æƒ…æ„Ÿä¿¡æ¯ï¼Œä»æƒ…æ„Ÿç´¢å¼•ä¸­å¬å›å€™é€‰èŠ‚ç‚¹
        if (query_fp & SimHash::MASK_AFFECTIVE) != 0 {
            let emotion_hash = ((query_fp & SimHash::MASK_AFFECTIVE) >> 48) as u8;
            for i in 0..8 {
                if (emotion_hash & (1 << i)) != 0 {
                    if let Some(candidates) = self.affective_index.get(&(1 << i)) {
                         for &id in candidates {
                            let entry = activated_keywords.entry(id).or_insert(0.0);
                            // æƒ…æ„Ÿå…±æŒ¯èƒ½é‡è®¾ä¸º 0.7 (æ¯”è¾ƒå¼ºçƒˆï¼Œå› ä¸ºæ˜¯å†…å¿ƒçš„ç›´æ¥æŠ•å°„)
                            if *entry < 0.7 { *entry = 0.7; }
                        }
                    }
                }
            }
        }

        // --- Step 2: ç¬¬ä¸€æ•°æ®åº“ (Ontology å®šä¹‰åº“) æ‰©æ•£ ---
        let mut ontology_expanded = activated_keywords.clone();
        for (&node_id, &score) in &activated_keywords {
            if let Some(neighbors) = self.ontology_graph.get(&node_id) {
                for edge in neighbors {
                    let weight = edge.connection_strength as f32 / 65535.0;
                    
                    // V2: åå‘æŠ‘åˆ¶ (Inverse Inhibition) - é™ä½æ³›åŒ–è¯æƒé‡
                    let degree = self.in_degrees.get(&edge.target_node_id).unwrap_or(&1);
                    // log10(1)=0 -> 1.0; log10(10)=1 -> 0.5; log10(100)=2 -> 0.33
                    let inhibition_factor = 1.0 / (1.0 + (*degree as f32).log10()); 
                    
                    // V3.5: ç±»å‹åŒ–è¾¹é€»è¾‘
                    // 1. EQUALITY (1): é›¶æŸè€—ï¼Œæ— è§†åå‘æŠ‘åˆ¶ï¼Œèƒ½é‡ç›´æ¥ä¼ é€’ (max)
                    // 2. INHIBITION (255): è´Ÿèƒ½é‡æ‰£å‡
                    // 3. REPRESENTATION (0): æ­£å¸¸è¡°å‡
                    
                    if edge.edge_type == SimHash::EDGE_EQUALITY {
                        // ç­‰ä»·ä¼ é€’ï¼šç›´æ¥å–æºèŠ‚ç‚¹èƒ½é‡ï¼Œä¸æ‰“æŠ˜
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        if score > *entry {
                             *entry = score;
                        }
                        continue;
                    }
                    
                    // è®¡ç®—åŸºç¡€èƒ½é‡ (å«æƒé‡å’Œåå‘æŠ‘åˆ¶)
                    let energy = score * weight * 0.95 * inhibition_factor;
                    
                    if edge.edge_type == SimHash::EDGE_INHIBITION {
                        // æŠ‘åˆ¶ä¼ é€’ï¼šæ‰£å‡èƒ½é‡
                        // æ³¨æ„ï¼šå¦‚æœç›®æ ‡èŠ‚ç‚¹å°šæœªæ¿€æ´» (0.0)ï¼Œæ‰£å‡åä¸ºè´Ÿï¼Œä¹‹åä¼šè¢«æˆªæ–­
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        *entry -= energy; 
                    } else {
                        // æ™®é€šä¼ é€’
                        // V2: ç¡¬é˜ˆå€¼å‰ªæ (Hard Squelch)
                        if energy < 0.05 { continue; }
                        
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        *entry = (*entry).max(energy);
                    }
                }
            }
        }

        // --- Step 3: èƒ½é‡å½’ä¸€åŒ– (Energy Normalization) ---
        // é˜²æ­¢æ‰©æ•£åˆ° Memory åº“å‰èƒ½é‡è¿‡å¤§
        let total_energy: f32 = ontology_expanded.values().sum();
        if total_energy > 10.0 {
            let factor = 10.0 / total_energy;
            for val in ontology_expanded.values_mut() {
                *val *= factor;
            }
        }

        // --- Step 4: ç¬¬äºŒæ•°æ®åº“ (Memory è®°å¿†åº“) æ‰©æ•£ ---
        let final_scores = ontology_expanded.clone();
        let decay = 0.85; // æé«˜è¡°å‡ç³»æ•°ï¼Œå¢åŠ ä¿¡å·ä¼ æ’­è·ç¦»
        let layer_limit = 5000; 

        // ä¾§å‘æŠ‘åˆ¶ï¼šé€‰å‡ºèƒ½é‡æœ€é«˜çš„ Top-K ç§å­è¿›è¡Œæ‰©æ•£
        let mut seeds: Vec<(&i64, &f32)> = ontology_expanded.iter().collect();
        // æ’åº
        seeds.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
        // æˆªæ–­ (Lateral Inhibition)
        if seeds.len() > layer_limit {
            seeds.truncate(layer_limit);
        }

        let increments: AHashMap<i64, f32> = seeds
            .into_par_iter()
            .fold(
                || AHashMap::new(),
                |mut acc, (&node_id, &score)| {
                    if let Some(neighbors) = self.graph.get(&node_id) {
                        for edge in neighbors {
                            let weight = edge.connection_strength as f32 / 65535.0;
                            
                            // V2: åå‘æŠ‘åˆ¶ (Memory å±‚)
                            let degree = self.in_degrees.get(&edge.target_node_id).unwrap_or(&1);
                            let inhibition_factor = 1.0 / (1.0 + (*degree as f32).log10());

                            let energy = score * weight * decay * inhibition_factor;
                            
                            // Memory å±‚é˜ˆå€¼ç¨ä½ï¼Œä¿ç•™æ›´å¤šç»†èŠ‚
                            if energy < 0.01 { continue; } 

                            *acc.entry(edge.target_node_id).or_default() += energy;
                        }
                    }
                    acc
                },
            )
            .reduce(
                || AHashMap::new(),
                |mut m1, m2| {
                    for (k, v) in m2 { *m1.entry(k).or_default() += v; }
                    m1
                },
            );

        // --- Step 5: ç»“æœæ•´åˆä¸å±€éƒ¨ SimHash ç»†åŒ– ---
        let mut results_map = final_scores;
        for (id, energy) in increments {
            *results_map.entry(id).or_default() += energy;
        }

        let mut results: Vec<_> = results_map
            .into_iter()
            .filter(|(id, _)| self.nodes.get(id).map_or(false, |n| n.node_type == NodeType::Event))
            .collect();

        // å±€éƒ¨ç»†åŒ–ï¼šåªå¯¹åˆæ­¥æ’åºå‰ 50 çš„ç»“æœè¿›è¡Œ SimHash ä¿®æ­£
        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        for i in 0..results.len().min(50) {
            let (id, score) = &mut results[i];
            if let Some(node) = self.nodes.get(id) {
                // V2: åˆ†åŒºå¤šæ¨¡æ€å…±æŒ¯é€»è¾‘
                // 1. è¯­ä¹‰å…±æŒ¯ (åŸºç¡€)
                let semantic_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_SEMANTIC);
                let mut resonance_boost = semantic_sim * 0.6; // æ˜¾è‘—æå‡è¯­ä¹‰å…±æŒ¯æƒé‡
                
                // 2. æ—¶é—´å…±æŒ¯ (Temporal Resonance)
                // åªæœ‰å½“ Query æ˜¾å¼åŒ…å«æ—¶ç©ºä¿¡æ¯æ—¶ (mask åŒºåŸŸéé›¶)ï¼Œæ‰è¿›è¡ŒåŠ æƒ
                if (query_fp & SimHash::MASK_TEMPORAL) != 0 {
                    let temporal_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_TEMPORAL);
                    // æ—¶ç©ºåŒ¹é…ç»™äºˆé«˜æƒé‡ (0.5)ï¼Œæ¨¡æ‹Ÿâ€œç¬é—´å›å¿†â€
                    resonance_boost += temporal_sim * 0.5;
                }

                // 3. æƒ…æ„Ÿå…±é¸£ (Affective Resonance) - Bitwise AND
                if (query_fp & SimHash::MASK_AFFECTIVE) != 0 {
                    let query_emotions = (query_fp & SimHash::MASK_AFFECTIVE) >> 48;
                    let node_emotions = (node.fingerprint & SimHash::MASK_AFFECTIVE) >> 48;
                    
                    // ä½è¿ç®—å…±æŒ¯ï¼šåªè¦æœ‰å…±åŒçš„æƒ…æ„Ÿä½è¢«æ¿€æ´»ï¼Œå°±äº§ç”Ÿå¼ºçƒˆå…±é¸£
                    if (query_emotions & node_emotions) != 0 {
                        resonance_boost += 0.6; 
                    }
                }

                // 4. ç±»å‹å¯¹é½ (Entity Type Alignment)
                if (query_fp & SimHash::MASK_TYPE) != 0 {
                    let type_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_TYPE);
                    // ç±»å‹åŒ¹é…ç»™äºˆæé«˜çš„ä¿®æ­£æƒé‡ (0.8)ï¼Œå› ä¸ºç±»å‹ä¸å¯¹é€šå¸¸æ„å‘³ç€å®Œå…¨æ— å…³
                    resonance_boost += type_sim * 0.8;
                }

                // 5. è‰¾å®¾æµ©æ–¯è®°å¿†è¡°å‡ (Ebbinghaus Decay)
                // Formula: Energy = Base * e^(-t/tau)
                // ä½¿ç”¨ä¼ å…¥çš„ ref_time ä½œä¸ºè¡°å‡åŸºå‡†æ—¶é—´ (å¦‚æœä¸º 0 åˆ™é»˜è®¤ä¸è¡°å‡)
                let current_decay_time = if ref_time > 0 { ref_time } else { 1777593600 }; 
                let tau = 31536000.0; // å»¶é•¿è®°å¿†åŠè¡°æœŸ
                
                if node.timestamp > 0 && node.timestamp < current_decay_time {
                    let delta_t = (current_decay_time - node.timestamp) as f32;
                    let decay_factor = (-delta_t / tau).exp();
                    
                    // é™ä½è¡°å‡æ€»æƒé‡ï¼šé™åˆ¶è¡°å‡ç³»æ•°æœ€ä½ä¸º 0.8 (æ—§è®°å¿†æœ€å¤šæŸå¤± 20% èƒ½é‡)
                    let final_decay = decay_factor.max(0.8);
                    *score *= final_decay;
                }

                *score += resonance_boost;
            }
        }

        // --- ç¬¬å››é˜¶æ®µï¼šæ··æ²Œæ¿€æ´» (åŒè½¨å¹¶è¡Œ) ---
        if chaos_level > 0.0 {
            if let Some((query_fp, query_vec_f16)) = self.calculate_chaos(query) {
                let mut combined_results = AHashMap::new();
                
                // å°†ç†æ€§æ£€ç´¢ç»“æœå­˜å…¥ map (æŒ‰ 1 - chaos_level åŠ æƒ)
                for (id, score) in results.iter() {
                    combined_results.insert(*id, *score * (1.0 - chaos_level));
                }

                // --- 1. L1 ç²—æ’ (1-bit é‡åŒ–) ---
                // è®¡ç®—æ‰€æœ‰äº‹ä»¶èŠ‚ç‚¹çš„æ±‰æ˜è·ç¦»
                // ä¿ç•™å‰ 5000 ä¸ªå€™é€‰è€…
                
                // SoA æ‰«æ
                let mut candidates: Vec<(usize, u32)> = Vec::with_capacity(self.chaos_store.ids.len() / 10);

                for (idx, &node_fp) in self.chaos_store.fingerprints.iter().enumerate() {
                    // æ±‰æ˜è·ç¦»ï¼šå¼‚æˆ– -> ä½è®¡æ•° (ä¸åŒä½çš„æ•°é‡)
                    let distance = query_fp.hamming_distance(&node_fp);
                    
                    // é˜ˆå€¼å‰ªæï¼šæœ€å¤§è·ç¦» 256 (æ€»å…± 512 ä½) æ„å‘³ç€ç›¸å…³æ€§å‡ ä¹ä¸º 0
                    if distance < 256 {
                        candidates.push((idx, distance));
                    }
                }

                // æŒ‰è·ç¦»æ’åº (å‡åº)
                candidates.sort_unstable_by_key(|k| k.1);
                
                // æˆªå–å‰ 5000 ä¸ª
                if candidates.len() > 5000 {
                    candidates.truncate(5000);
                }

                // --- 2. L2 ç²¾æ’ (f16 ä½™å¼¦ç›¸ä¼¼åº¦) ---
                let q_norm: f32 = query_vec_f16.iter().map(|x| x.to_f32().powi(2)).sum::<f32>().sqrt();
                
                for (idx, _dist) in candidates {
                    let node_id = self.chaos_store.ids[idx];
                    let chaos_vector = &self.chaos_store.vectors[idx];

                    if !chaos_vector.is_empty() {
                        let dot: f32 = query_vec_f16.iter().zip(chaos_vector).map(|(a, b)| a.to_f32() * b.to_f32()).sum();
                        let n_norm: f32 = chaos_vector.iter().map(|x| x.to_f32().powi(2)).sum::<f32>().sqrt();
                        
                        if q_norm > 0.0 && n_norm > 0.0 {
                            let sim = dot / (q_norm * n_norm);
                            
                            // éçº¿æ€§æ¿€æ´» (é˜ˆå€¼ > 0.6, æœ€å¤§ç³»æ•° 0.15)
                            if sim > 0.6 {
                                let normalized = (sim - 0.6) / 0.4;
                                let chaos_score = normalized * 0.15;
                                let weighted_chaos = chaos_score * chaos_level;
                                
                                *combined_results.entry(node_id).or_default() += weighted_chaos;
                            }
                        }
                    }
                }
                
                // è½¬æ¢å›æ’åºåçš„å‘é‡
                let mut final_results: Vec<_> = combined_results.into_iter().collect();
                final_results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
                return final_results;
            }
        }
        
        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        results
    }

    /// æ¨¡æ‹Ÿ LLM ç»´æŠ¤è¿‡ç¨‹ï¼šå¯¹è¯ååˆ†æå…³é”®è¯å…³è”å¹¶æ›´æ–° Ontology
    /// V2: é€»è¾‘ä»²è£è§¦å‘å™¨ (Logical Arbitration Trigger)
    /// å½“ action ä¸º "replace" æ—¶è°ƒç”¨æ­¤å‡½æ•°
    /// è¿”å›å€¼ï¼šéœ€è¦å‘é€ç»™ LLM2 (ä»²è£è€…) çš„ Context (å±€éƒ¨å­å›¾æ–‡æœ¬)
    pub fn trigger_arbitration(&self, source: &str) -> Option<String> {
        let src_id = self.keyword_to_node.get(&source.to_lowercase())?;
        
        // æå– 1-hop å­å›¾
        // æ ¼å¼: "Source -> Target (Strength: 0.x)"
        let mut context_lines = Vec::new();
        if let Some(edges) = self.ontology_graph.get(src_id) {
            for edge in edges {
                if let Some(target_node) = self.nodes.get(&edge.target_node_id) {
                    let strength = edge.connection_strength as f32 / 65535.0;
                    context_lines.push(format!("{} -> {} (Strength: {:.2})", 
                        source, target_node.content, strength));
                }
            }
        }
        
        if context_lines.is_empty() {
            return None;
        }
        
        Some(context_lines.join("\n"))
    }

    /// V2: æ‰§è¡Œä»²è£ç»“æœ (Apply Arbitration)
    /// æ ¹æ® LLM2 çš„æŒ‡ç¤ºåˆ é™¤æŒ‡å®šå…³è”
    pub fn apply_arbitration(&mut self, source: &str, delete_targets: Vec<String>) {
        if let Some(&src_id) = self.keyword_to_node.get(&source.to_lowercase()) {
            if let Some(edges) = self.ontology_graph.get_mut(&src_id) {
                let initial_len = edges.len();
                
                // è¿‡æ»¤æ‰éœ€è¦åˆ é™¤çš„ç›®æ ‡
                // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é€šè¿‡ target content åæŸ¥ idï¼Œæˆ–è€…éå† edges æ£€æŸ¥ content
                // ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬å…ˆæ”¶é›†è¦åˆ é™¤çš„ target_ids
                let mut target_ids_to_remove = Vec::new();
                
                for target_str in delete_targets {
                    if let Some(&tgt_id) = self.keyword_to_node.get(&target_str.to_lowercase()) {
                        target_ids_to_remove.push(tgt_id);
                    }
                }
                
                if !target_ids_to_remove.is_empty() {
                    edges.retain(|e| !target_ids_to_remove.contains(&e.target_node_id));
                    let removed_count = initial_len - edges.len();
                    if removed_count > 0 {
                        println!("âœ‚ï¸ [Arbitration] å·²ä» '{}' ç§»é™¤ {} æ¡è¿‡æ—¶å…³è”", source, removed_count);
                    }
                }
            }
        }
    }

    /// ç»Ÿä¸€ç»´æŠ¤æ¥å£ (Unified Maintenance Interface)
    /// è‡ªåŠ¨å¤„ç† upsert/replace é€»è¾‘
    /// è¿”å›å€¼: Option<String> - å¦‚æœéœ€è¦ä»²è£ (Replace æ¨¡å¼)ï¼Œè¿”å› 1-hop å±€éƒ¨å­å›¾ä¸Šä¸‹æ–‡ï¼›å¦åˆ™è¿”å› None
    pub fn execute_maintenance(&mut self, action: &str, source: &str, target: &str, relation_type: &str, strength: f32, _reason: &str) -> Option<String> {
        match action.to_lowercase().as_str() {
            "upsert" => {
                // Upsert: ç›´æ¥ç»´æŠ¤æœ¬ä½“å…³è”
                self.maintain_ontology(source, target, relation_type, strength);
                None
            },
            "replace" => {
                // Replace: å…ˆåº”ç”¨æ–°å˜æ›´ï¼Œç„¶åè§¦å‘ä»²è£
                // è¿™æ · LLM2 èƒ½çœ‹åˆ°å†²çªçš„å…¨è²Œ (æ—§ + æ–°)
                self.maintain_ontology(source, target, relation_type, strength);
                self.trigger_arbitration(source)
            },
            _ => {
                println!("âš ï¸ æœªçŸ¥æ“ä½œ: {} (Source: {})", action, source);
                None
            }
        }
    }
}

fn run_ten_million_test(count: usize) {
    println!("ğŸ”¥ å¼€å§‹æ‰§è¡Œåƒä¸‡çº§å‹åŠ›æµ‹è¯• (ç›®æ ‡: {} èŠ‚ç‚¹) ğŸ”¥", count);
    let mut engine = AdvancedEngine::new();
    
    // è‡ªåŠ¨åŠ è½½æ¨¡å‹ä»¥æ”¯æŒæ··æ²Œæ£€ç´¢æµ‹è¯•
    let model = embedding::CandleModel::new().ok();
    if let Some(m) = model {
        println!("ğŸ§  å·²è‡ªåŠ¨åŠ è½½ {}ç»´ Candle å‘é‡æ¨¡å‹ç”¨äºå‹åŠ›æµ‹è¯•", m.dimension);
        engine.embedding_model = Some(m);
    }
    
    // åŠ è½½æ•°æ®
    engine.load_million_test_data(count);
    
    // ç¼–è¯‘
    let start_compile = Instant::now();
    engine.compile();
    println!("âš™ï¸ å¼•æ“ç¼–è¯‘è€—æ—¶: {:?}", start_compile.elapsed());
    
    // 1. çº¯ç†æ€§æ£€ç´¢æµ‹è¯• (chaos_level = 0.0)
    let query = "è¿™æ˜¯ä¸€ä¸ªå…³äº feat_42 å’Œ feat_999 çš„æ¨¡æ‹ŸæŸ¥è¯¢";
    println!("\nğŸ” [1/2] æ‰§è¡Œçº¯ç†æ€§æ£€ç´¢ (chaos_level = 0.0): \"{}\"", query);
    let start_retrieve_r = Instant::now();
    let results_r = engine.retrieve(query, 0, 0.0);
    println!("â±ï¸ æ£€ç´¢è€—æ—¶: {:?}", start_retrieve_r.elapsed());
    println!("ğŸ“Š å¬å›ç»“æœæ•°é‡: {}", results_r.len());
    
    // 2. åŒè½¨æ£€ç´¢æµ‹è¯• (chaos_level = 0.5)
    println!("\nğŸ” [2/2] æ‰§è¡ŒåŒè½¨èåˆæ£€ç´¢ (chaos_level = 0.5): \"{}\"", query);
    let start_retrieve_h = Instant::now();
    let results_h = engine.retrieve(query, 0, 0.5);
    println!("â±ï¸ æ£€ç´¢è€—æ—¶: {:?}", start_retrieve_h.elapsed());
    println!("ğŸ“Š å¬å›ç»“æœæ•°é‡: {}", results_h.len());
    
    if let Some((id, score)) = results_h.first() {
        if let Some(node) = engine.nodes.get(id) {
            println!("ğŸ” æœ€é«˜åˆ†ç»“æœ: ID={}, Score={:.4}", id, score);
            println!("ğŸ“ å†…å®¹æ‘˜è¦: {}", node.content);
        }
    }
    
    println!("\nâœ… åƒä¸‡çº§å‹åŠ›æµ‹è¯•å®Œæˆã€‚");
}

fn main() {
    let args: Vec<String> = std::env::args().collect();
    
    // V3 åŸºå‡†æµ‹è¯•æ¨¡å¼
    if args.contains(&"--v3".to_string()) || args.contains(&"--100m".to_string()) {
        let node_count = if args.contains(&"--100m".to_string()) { 
            100_000_000 
        } else if args.contains(&"--10m".to_string()) {
            10_000_000
        } else if args.contains(&"--small".to_string()) {
            1_000
        } else { 
            1_000_000 
        };
        println!("ğŸš€ å¯åŠ¨ PEDSA V3 æ¶æ„éªŒè¯ (ç´¢å¼•-è½½ä½“åˆ†ç¦») - è§„æ¨¡: {} èŠ‚ç‚¹", node_count);
        
        let index_path = "pedsa_v3.idx";
        let data_path = "pedsa_v3.dat";

        // åœ¨æ­¤ä½œç”¨åŸŸå…¨å±€åŠ è½½æ¨¡å‹
        let model = embedding::CandleModel::new().ok();
        if let Some(m) = &model {
            println!("ğŸ§  å·²åŠ è½½ {}ç»´ Candle å‘é‡æ¨¡å‹ (BGE-Small-ZH)", m.dimension);
        }

        // --- é˜¶æ®µ 3: ä¸ºåŠ æƒå‘é‡åŒ–å‡†å¤‡ AC è‡ªåŠ¨æœº ---
        println!("ğŸ”§ [Phase 3] åˆå§‹åŒ–åŠ æƒå‘é‡åŒ–ç»„ä»¶ (AC Automaton)...");
        let mut keywords = Vec::new();
        // åŠ è½½æœ¬ä½“å…³é”®è¯
        for edge in get_ontology_data() {
            keywords.push(edge.src.to_string());
            keywords.push(edge.tgt.to_string());
        }
        // æ·»åŠ æµ‹è¯•æŸ¥è¯¢çš„æ¼”ç¤ºå…³é”®è¯
        keywords.push("çƒ­æ’å…¥".to_string());
        keywords.push("æ··åˆæ‰«æ".to_string());
        keywords.push("Chaos".to_string());
        keywords.push("SIMD".to_string());
        
        // å»é‡
        keywords.sort();
        keywords.dedup();
        
        let ac_matcher = AhoCorasickBuilder::new()
            .match_kind(MatchKind::LeftmostLongest)
            .build(&keywords)
            .ok();
        
        if ac_matcher.is_some() {
            println!("âœ… AC è‡ªåŠ¨æœºæ„å»ºå®Œæˆï¼ŒåŒ…å« {} ä¸ªå…³é”®è¯", keywords.len());
        }

        // 1. æ£€æŸ¥æˆ–ç”Ÿæˆæ•°æ®
        if !std::path::Path::new(index_path).exists() {
            let start_gen = Instant::now();
            
            // å®šä¹‰å‘é‡åŒ–é—­åŒ…
            let vectorizer = |text: &str| -> Vec<f16> {
                if let Some(m) = &model {
                    if let Some(v) = m.vectorize(text) {
                         return v.into_iter().map(f16::from_f32).collect();
                    }
                }
                vec![f16::from_f32(0.01); 512]
            };

            if let Err(e) = generate_binary_dataset(node_count, index_path, data_path, vectorizer) {
                eprintln!("âŒ ç”Ÿæˆå¤±è´¥: {}", e);
                return;
            }
            println!("ğŸ’¾ æ•°æ®ç”Ÿæˆè€—æ—¶: {:?}", start_gen.elapsed());
        }

        // 2. æé€ŸåŠ è½½ (mmap)
        println!("\nğŸ“¥ æ­£åœ¨åŠ è½½ V3 å­˜å‚¨å¼•æ“ (mmap)...");
        let start_load = Instant::now();
        let mut storage = match StorageEngine::new(index_path, data_path) {
            Ok(s) => s,
            Err(e) => {
                eprintln!("âŒ åŠ è½½å¤±è´¥: {}", e);
                return;
            }
        };
        println!("âš¡ V3 åŠ è½½å®Œæˆ! è€—æ—¶: {:?} (åŒ…å« Header è§£æ)", start_load.elapsed());

        // æµ‹è¯•çƒ­æ’å…¥
            println!("ğŸ“¥ æ­£åœ¨æµ‹è¯•çƒ­æ’å…¥åŠŸèƒ½...");
            let hot_node_text = "è¿™æ˜¯é€šè¿‡çƒ­æ’å…¥æ·»åŠ çš„æ–°èŠ‚ç‚¹ï¼Œç”¨äºéªŒè¯ LSM-tree æ··åˆæ‰«æã€‚";
            let hot_node_fp = SimHash::compute_multimodal(hot_node_text, 0, 0, 0);
            
            // Chaos å‘é‡ç”Ÿæˆ
            let chaos_vec = if let Some(m) = &model {
                 if let Some(v) = m.vectorize(hot_node_text) {
                     v.into_iter().map(f16::from_f32).collect()
                 } else {
                     vec![f16::from_f32(0.0); 512]
                 }
            } else {
                 vec![f16::from_f32(0.0); 512]
            };
            let chaos_fp = StorageEngine::quantize_vector(&chaos_vec);
            
            storage.insert_node(999999999, hot_node_fp, hot_node_text.to_string(), 1, chaos_fp, &chaos_vec);
            println!("âœ… å·²æˆåŠŸçƒ­æ’å…¥æ–°èŠ‚ç‚¹ (ID: 999999999)");

        println!("ğŸ“š èŠ‚ç‚¹æ€»æ•°: {} (ç£ç›˜: {} + ç¼“å†²åŒº: 1)", storage.node_count(), node_count);

        // 3. æ¨¡æ‹Ÿå…±æŒ¯æ£€ç´¢ (SIMD åŠ é€Ÿ)
    let query = "éªŒè¯çƒ­æ’å…¥çš„æ··åˆæ‰«æ";
    let query_fp = SimHash::compute_multimodal(query, 0, 0, 0);
    
    println!("\nğŸ” å¼€å§‹æ‰§è¡Œ {} èŠ‚ç‚¹å…¨é‡æ··åˆæ‰«æ (SIMD + Buffer)...", storage.node_count());
    let start_scan = Instant::now();
    
    let (idx, score) = storage.scan_simd(query_fp);

    let duration = start_scan.elapsed();
    println!("â±ï¸ SimHash æ‰«æè€—æ—¶: {:?}", duration);
    
    println!("ğŸ” Top-1 Index: {}, Score: {:.4}", idx, score);
    println!("ğŸ†” Node ID: {}", storage.get_id(idx));
    // åªæœ‰åœ¨è¿™é‡Œæ‰å»è§¦ç¢°å†·æ•°æ®
    println!("ğŸ“ æ‡’åŠ è½½æ–‡æœ¬: {}", storage.get_node_text_by_idx(idx));

    // --- Chaos å‘é‡æ‰«æ ---
    println!("\nğŸ§  æ‰§è¡Œ Chaos Vector è¯­ä¹‰æ£€ç´¢ (Top-5)...");
    let start_vec = Instant::now();
    let query_vec = if let Some(m) = &model {
         // é˜¶æ®µ 3: åŠ æƒå‘é‡åŒ–
         let weighted_ranges = Vec::new();
         // ... (AC åŒ¹é…é€»è¾‘å·²çœç•¥ï¼Œå› ä¸ºä¸å†åœ¨ vectorize_weighted ä¸­ä½¿ç”¨)

         if let Some(v) = m.vectorize_weighted(query, &weighted_ranges) {
            v.into_iter().map(f16::from_f32).collect()
        } else {
            vec![f16::from_f32(0.0); 512]
        }
    } else {
        vec![f16::from_f32(0.0); 512]
    };

    let vec_results = storage.scan_vector_top_k(&query_vec, 5);
    let vec_duration = start_vec.elapsed();
    println!("â±ï¸ Vector æ‰«æè€—æ—¶: {:?}", vec_duration);
    
    for (rank, (v_idx, v_score)) in vec_results.iter().enumerate() {
        let node_id = storage.get_id(*v_idx);
        
        // æ£€ç´¢ Chaos æŒ‡çº¹å’Œå‘é‡ä»¥æ¼”ç¤ºè®¿é—®
        let fingerprint = storage.get_chaos_fingerprint_by_idx(*v_idx);
        let vector = storage.get_chaos_vector_by_idx(*v_idx);
        
        let text = storage.get_node_text_by_idx(*v_idx);
        println!("   #{}: ID={}, Score={:.4}, FP={:032x}, VecLen={}, Text={}", 
                 rank+1, node_id, v_score, fingerprint, vector.len(), text);
    }

    // --- æ··åˆæ‰«æ (Chaos FP u128 -> Chaos Vec f16) ---
    println!("\nâš¡ æ‰§è¡Œ Hybrid Scan (L1 Chaos FP u128 -> L2 Chaos Vector)...");
    let query_chaos_fp = StorageEngine::quantize_vector(&query_vec);
    println!("   Query Chaos FP: {:032x}", query_chaos_fp);

    let start_hybrid = Instant::now();
    // L1: é€šè¿‡æ±‰æ˜è·ç¦»æ£€ç´¢å‰ 1000 ä¸ªå€™é€‰è€…
    // L2: é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦é‡æ–°æ’åºå‰ 1000 ä¸ª
    let hybrid_results = storage.search_hybrid(query_chaos_fp, &query_vec, 5, 1000); 
    let hybrid_duration = start_hybrid.elapsed();
    println!("â±ï¸ Hybrid æ‰«æè€—æ—¶: {:?}", hybrid_duration);

    for (rank, (v_idx, v_score)) in hybrid_results.iter().enumerate() {
        let node_id = storage.get_id(*v_idx);
        let text = storage.get_node_text_by_idx(*v_idx);
        println!("   #{}: ID={}, Score={:.4}, Text={}", 
                 rank+1, node_id, v_score, text);
    }

    // --- æ¨¡æ‹Ÿ V2 åŒå±‚æ£€ç´¢æ¶æ„ ---
    println!("\nğŸ­ æ¨¡æ‹Ÿ V2 åŒå±‚æ£€ç´¢æ¶æ„ (Ontology vs Event):");
    
    // Step 1: æ‰«æ Ontology (node_type = 0)
    let start_ont = Instant::now();
    let (ont_idx, ont_score) = storage.scan_simd_filtered(query_fp, Some(0));
    println!("   ğŸ§  Ontology æœ€ä½³åŒ¹é…: ID={}, Score={:.4} (è€—æ—¶: {:?})", 
             storage.get_id(ont_idx), ont_score, start_ont.elapsed());
    
    // Step 2: æ‰«æ Event (node_type = 1)
    let start_evt = Instant::now();
    let (evt_idx, evt_score) = storage.scan_simd_filtered(query_fp, Some(1));
    println!("   ğŸ“… Event æœ€ä½³åŒ¹é…:    ID={}, Score={:.4} (è€—æ—¶: {:?})", 
             storage.get_id(evt_idx), evt_score, start_evt.elapsed());

    // æ‰“å°å†…å­˜å ç”¨æç¤º
    println!("\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥ä»»åŠ¡ç®¡ç†å™¨ä¸­çš„å†…å­˜å ç”¨ã€‚");
        let expected_mem = (node_count as f64 * 32.0) / (1024.0 * 1024.0);
        println!("   é¢„æœŸ: æ˜¾å­˜/ç‰©ç†å†…å­˜ä»…å ç”¨çº¦ {:.2}MB (32 bytes * {} nodes)", expected_mem, node_count);
        return;
    }

    if args.contains(&"--million".to_string()) || args.contains(&"--10m".to_string()) {
        run_ten_million_test(10_000_000);
        return;
    }

    println!("=== PEDSA RAG-less é«˜çº§å®éªŒæ¡†æ¶ ===");
    let mut engine = AdvancedEngine::new();

    // 0. åŠ è½½æ¨¡å‹ (å¦‚æœå­˜åœ¨)
    if let Ok(model) = embedding::CandleModel::new() {
        println!("ğŸ§  å·²åŠ è½½ {}ç»´ Candle å‘é‡æ¨¡å‹ (BGE-M3 GGUF)", model.dimension);
        engine.embedding_model = Some(model);
    }

    // 1. åŠ è½½æ•°æ®ä¸å»ºç«‹æ—¶åºè„Šæ¢
    engine.load_standard_data();

    // 2. ç¼–è¯‘å¼•æ“
    engine.compile();

    // 3. æ‰§è¡Œæµ‹è¯•åœºæ™¯
    tests::run_all_scenarios(&mut engine);
}
